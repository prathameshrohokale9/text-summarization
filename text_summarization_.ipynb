{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pq0K8r5PPhBR"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import string\n",
        "from heapq import nlargest"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/prathamesh.txt\",\"r\", encoding=\"utf8\") as f: \n",
        "    text=f.read()"
      ],
      "metadata": {
        "id": "xpxzacToPmiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#/prathamesh.txt is path of directory you can change this "
      ],
      "metadata": {
        "id": "uK1tjl96W3FV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(text)"
      ],
      "metadata": {
        "id": "QP4MxBtYWoXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "#print(STOPWORDS)\n",
        "print(\"there are {} words in all text.\". format(len(text)))\n",
        "WC=WordCloud(stopwords=STOPWORDS, background_color=\"white\").generate(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcN_B9q-XoYx",
        "outputId": "5725b9cb-a40f-4d91-fe16-17705e49a568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "there are 5864 words in all text.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "print(text.count(\".\"))\n",
        "print(string.punctuation)\n",
        "nopuch=[char for char in text if char not in string.punctuation]\n",
        "nopuch=\"\".join(nopuch)\n",
        "#print(nopuch)\n",
        "\n",
        "process_text=[word for word in nopuch.split() if word.lower() not in nltk.corpus.stopwords.words('english')]\n",
        "#print(process_text)\n",
        "\n",
        "#create word freq\n",
        "word_freq={}\n",
        "for word in process_text:\n",
        "    if word not in word_freq:\n",
        "        word_freq[word]=1\n",
        "    else:\n",
        "        word_freq[word]=word_freq[word]+1\n",
        "\n",
        "#dict(sorted(word_freq.items(),key=lambda item:item[1], reverse=True))\n",
        "\n",
        "max_freq=max(word_freq.values())\n",
        "\n",
        "for word in word_freq.keys():\n",
        "    word_freq[word]=(word_freq[word]/max_freq)\n",
        "\n",
        "#create sent freq\n",
        "sent_list=nltk.sent_tokenize(text)\n",
        "\n",
        "sent_score={}\n",
        "for sent in sent_list:\n",
        "    for word in nltk.word_tokenize(sent.lower()):\n",
        "        if word in word_freq.keys():\n",
        "            if sent not in sent_score.keys():\n",
        "                sent_score[sent]=word_freq[word]\n",
        "            else:\n",
        "                sent_score[sent]=sent_score[sent]+word_freq[word]\n",
        "                \n",
        "#dict(sorted(sent_score.items(),key=lambda item:item[1], reverse=True))\n",
        "       \n",
        "summary_sent=nlargest(3,sent_score, key=sent_score.get)\n",
        "\n",
        "summary=\" \".join(summary_sent)\n",
        "\n",
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "SzfXlSsCXxH4",
        "outputId": "e52f12e8-592a-45e1-8d60-7f6cb8068020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42\n",
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Simulated experiments with synthetic flows and a case study using Beijing\\ntaxi trip data are conducted to validate the usefulness of the proposed method\\nIts main objective is to provide an integrated monitoring system such as vehicle location\\ntracking, speed and route monitoring, total distance travel report, and anti-car theft that helps\\nprivate individuals, companies, and government agencies about the status and location of their\\nvehicles they want to monitor. By adding layers of geographic\\ndata—such as demographics, traffic, and weather—to a smart map or dashboard,\\norganizations can use intelligence tools to identify where an event has taken place,\\nunderstand why it is happening, and gain insight into what caused it. AirTag is designed to act as a key finder,\\nwhich helps people find personal objects To locate lost items, AirTags use Apple's\\ncrowdsourced Find My network, estimated in early 2021 to consist of approximately one\\nbillion devices worldwide that detect and anonymously report emitted Bluetooth signals.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}